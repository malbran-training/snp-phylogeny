{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phylogeny from whole genome sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we sequence a population, we aim to capture the variation (SNPs, indels, gene gain and loss etc.) in the samples and use it to infer the relationships between the samples. Two of the main approaches to capturing this variation and reconstructing the bacterial genomes are:\n",
    "\n",
    "* De novo genome assembly and annotation\n",
    "* Mapping and variant calling against a reference genome\n",
    "\n",
    "Each approach has it's benefits and limitations. We will focus on mapping and variant calling in this tutorial. For mapping and variant calling, whether we are dealing with different bacterial isolates, with viral populations in a patient, or even with genomes of different human individuals, the principles are essentially the same. Instead of assembling the newly generated sequence reads de novo to produce a new genome sequence, it is easier and much faster to align or map the sequence reads to a reference genome. We can then readily identify SNPs and indels that distinguish closely related populations or individual organisms and may thus learn about genetic differences that may cause drug resistance or increased virulence in pathogens, or changed susceptibility to disease in humans. One important prerequisite for the mapping of sequence data to work is that the reference and the re-sequenced subject have the same genome architecture.\n",
    "\n",
    "In this exercise, we will use sequence data from _Salmonella enterica serovar Typhi_ samples to demonstrate the mapping and variant calling approach. Importantly, although the data is based on real sequence data, it has been edited to make it run more efficiently for the purpose of this tutorial.\n",
    "\n",
    "Navigate to the directory that contains the sequence data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/course_data/snp-phylogeny/data/typhi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the directory containing the sequence data for the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the tutorial dataset\n",
    "\n",
    "We will use data adapted from the following paper:\n",
    "\n",
    "> **A genomic snapshot of Salmonella enterica serovar Typhi in Colombia**  \n",
    "> Guevara, Paula Diaz, et al.  \n",
    "> _PLoS Neglected Tropical Diseases2021. doi: 10.1371/journal.pntd.0009755_  \n",
    "> PMID: [34529660](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8478212/) \n",
    "\n",
    "_Salmonella enterica serovar Typhi_ (_S. Typhi_) is the causative agent of typhoid fever, with between 9–13 million cases and 116,800 associated deaths annually. Typhoid fever is still a public health problem in many countries, including in Latin America, which has a modelled incidence of up to 169 (32–642) cases per 100,000 person-years. Several international studies have aimed to fill data gaps regarding the global distribution and genetic landscape of typhoid; however, in spite of these efforts Latin America is still underrepresented. This study provided the first enhanced insights into the molecular epidemiology of S. Typhi in Colombia, using whole genome sequencing data to investigate the population structure in Colombia and identify predominant circulating genotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of mapping and variant calling approach\n",
    "\n",
    "The diagram below illustrates the steps involved when mapping and calling variants for a set of bacterial samples.\n",
    "\n",
    "![Approach](img/snp-phylogeny-approach.png)\n",
    "\n",
    "The first step once you have obtained your sequence data (FASTQ) from the sequencing machine is to QC the data. After QC, the sequence data is matched or aligned to a reference genome (FASTA) in a process called read mapping to produce a set of read aligments (SAM/BAM). These read alignments are inspected to identify differences between the aligned reads and the reference genome. This process is called variant calling and produces VCF files. In fact during this process we capture information about every position in the genome (variant and non-variant sites) in the VCFs. Each site in the VCF has a set of quality filters applied and any sites identified as low quaility (e.g. less than 4 reads aligned at that position) are marked as low quality in the VCF to produce a filtered VCF. We use this filtered VCF file in a process called consensus caling to reconstruct a consensus _pseudosequence_ or _pseudogenome_ for our sample (FASTA). In the _pseudogenome_, any sites marked as low quality will be represented as an N in the reconstructed sequence. These pseudogenomes (multi-FASTA) are then aligned and variation identified and used to reconstruct a phylogeny of our samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Now let's analyse some data!\n",
    "\n",
    "### Prepare the data\n",
    "\n",
    "First take a look at the sequence data provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls fastq/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "\n",
    "1. How many samples have been sequenced?\n",
    "2. How many fastq files are there? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the chromosome sequence of _Salmonella typhi CT18_ as the reference genome. This has already been downloaded from RefSeq. Take a look at the reference genome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ref/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the reference file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly-stats ref/Styphi_CT18.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use bwa to index the reference genome. This creates a lookup table that bwa uses when matching the sequence reads against the reference genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwa index ref/Styphi_CT18.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "\n",
    "3. How many sequences in the reference fasta file?\n",
    "4. What are the names of the sequences in the reference fasta file?\n",
    "5. What is the size of the reference? \n",
    "6. What additional files did the indexing step produce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC the sequence data\n",
    "\n",
    "An important first step in any analysis is QC of the data. We will the FastQC software to QC the data. First create a directory for the qc results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd fastq\n",
    "mkdir qc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run FastQC on the all the fastq files and store the results in the directory `qc_results`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqc -o qc_results *.fastqc.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create one html report for each of the fastq files. Take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls qc_results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have lots of samples it will be difficult to manually inspect each file. Therefore we will use multiQC to collate all the QC reports into one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiqc qc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the collated report `multiqc_report.html` in firefox.\n",
    "\n",
    "![MultiQC results](img/multiqc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "\n",
    "1. What is the median read length for sample ERR5243693?\n",
    "2. Which sample has the largets yield (mose sequence data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim the reads to remove low quality and adapter sequence\n",
    "\n",
    "If your sequence reads have a high level of adapter contamination and/or have low quality bases at the end of the reads you can trim the reads to remove these sequences. There are several software that can be used to do this including trimmomatic and fastp.\n",
    "\n",
    "Use fastp to trim the reads for sample ERR5243693."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastp \\\n",
    "   --in1 ERR5243693_1.fastq.gz --in2 ERR5243693_2.fastq.gz \\\n",
    "   --out1 ERR5243693_1.trim.fastq.gz \\\n",
    "   --out2 ERR5243693_2.trim.fastq.gz \\\n",
    "   --json ERR5243693.fastp.json --html ERR5243693.fastp.html \\\n",
    "   --detect_adapter_for_pe --cut_mean_quality 20 \\\n",
    "   --thread 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat for the other samples.\n",
    "\n",
    "Take a look at the output from fastp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -20 ERR5243693.fastp.json\n",
    "head -20 ERR5243695.fastp.json\n",
    "head -20 ERR5243699.fastp.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "1. How much data (bp/base pairs) was lost due to trimming and adapter removal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the data to a reference genome "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use bwa to map the reads for sample ERR5243693 to the reference genome.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwa mem -t 2 ../ref/Styphi_CT18.fa \\\n",
    "ERR5243693_1.trim.fastq.gz ERR5243693_2.trim.fastq.gz > \\\n",
    "ERR5243693.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a few minutes to run. When complete, convert the sam file to a bam file with samtools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools view -@ 2 -bhS -o ERR5243693.bam ERR5243693.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort and index the sorted bam file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools sort -@ 1 -o ERR5243693.sorted.bam -T ERR5243693.sorted ERR5243693.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools index ERR5243693.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some statistics about the alignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools stats ERR5243693.sorted.bam > ERR5243693.stats\n",
    "samtools flagstat ERR5243693.sorted.bam > ERR5243693.flagstat\n",
    "samtools coverage ERR5243693.sorted.bam > ERR5243693.coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat for the other samples.\n",
    "\n",
    "#### Check your understanding\n",
    "1. What %reads mapped to the reference for each sample? \n",
    "2. What %genome was covered for each sample? \n",
    "3. What is the mean depth of coverage for each sample? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call variants\n",
    "\n",
    "Go through each position in the reference genome and look at reads aligned at that position and make a call about what the base is in the sample at that position. This information will be stored in the a VCF file and if there are any differences then this will be marked as a variant (snp/indel) in this VCF file. \n",
    "\n",
    "Do this for sample ERR5243693 using bcftools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools mpileup --fasta-ref ../ref/Styphi_CT18.fa \\\n",
    "--min-BQ 20 \\\n",
    "--annotate \\\n",
    "FORMAT/AD,FORMAT/ADF,FORMAT/ADR,FORMAT/DP,FORMAT/SP,INFO/AD,\\\n",
    "INFO/ADF,INFO/ADR ERR5243693.sorted.bam | bcftools call \\\n",
    "--output-type v --ploidy 1 --multiallelic-caller - | \\\n",
    "bcftools view --output-file ERR5243693.vcf.gz --output-type z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this may take some time to run. When it completes, index the VCF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabix -p vcf -f ERR5243693.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the VCF file that was produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools view ERR5243693.vcf.gz | less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the VCF has information about every site in the genome (not just variants).\n",
    "\n",
    "Now generate some statistics about the VCF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools stats ERR5243693.vcf.gz > ERR5243693.vcf.stats.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat for the other samples.\n",
    "\n",
    "Look at the statistics for the variant calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less ERR5243693.vcf.stats.txt\n",
    "less ERR5243695.vcf.stats.txt\n",
    "less ERR5243699.vcf.stats.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "1. How many sites are in the VCF file for each sample?\n",
    "2. Does this match to the size of the reference used in the read mappping step?\n",
    "3. How many variant sites were identified for each sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the VCFs\n",
    "We want to identify calls where we have a high confidence that they are correct (and not due to sequencing errors and/or misalignment of the reads). We use criteria like read depth at a position, quality scores etc. to filter out low quality calls at each position.\n",
    "\n",
    "Use bcftools to filter sites for sample ERR5243693."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools filter \\\n",
    "--output ERR5243693.filtered.vcf.gz \\\n",
    "--soft-filter LowQual --exclude \"QUAL<25 || FORMAT/DP<10 \\\n",
    "|| MAX(FORMAT/ADF)<2 || MAX(FORMAT/ADR)<2 || \\\n",
    "MAX(FORMAT/AD)/SUM(FORMAT/DP)<0.9 || MQ<30 || MQ0F>0.1\" \\\n",
    "--output-type z ERR5243693.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtering step may take some time ti run. When complete, index the filtered VCF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabix -p vcf -f ERR5243693.filtered.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the VCF file and notice how some of the sites are marked as `PASS` or `LowQual` under the filter column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools view ERR5243693.filtered.vcf.gz | less "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciew only the sites that passed the filtering step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools view -f PASS ERR5243693.filtered.vcf.gz | less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some statistics about the filtered VCF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools stats ERR5243693.filtered.vcf.gz > \\\n",
    "ERR5243693.filtered.stats.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat for the other samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "1. How many sites were marked as low quality in the filtering step?\n",
    "2. How many variant sites were marked as low quality in the filtering step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call a consensus sequence for each sample\n",
    "\n",
    "A pseudogenome is a reconstruction of what we think the genome is for the sample using the reference genome as a basis. To create it for a sample, you go through each position in the reference and determine what base is called (using the VCF from the previous steps) for the sample. Sometimes this will be the same as the reference, and sometimes it will differ from the reference (a variant). For positions that are flagged as low quality/filtered out (e.g. no reads covering the position) we use an N in the pseudogenome. This is because you cannot be confident what the base is at this position for the sample. In the end the length of the pseudogenome for your sample should be the same as the length of the reference. \n",
    "\n",
    "To create a pseudogenome for sample ERR5243693 use the script _vcf2pseudogenome.pl_. This has already been installed on the computer using this command:\n",
    "\n",
    "`wget https://raw.githubusercontent.com/nf-core/bactmap/master/bin/vcf2pseudogenome.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf2pseudogenome.py -r ../ref/Styphi_CT18.fa -b ERR5243693.filtered.vcf.gz -o ERR5243693.fas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat for the other samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "1. What is the length of the pseudogenomes? (Hint: Use assembly-stats)\n",
    "2. Does it match the length of the reference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a multiple sequence alignment of all pseudogenomes\n",
    "\n",
    "Remember to reconstruct the phylogeny of samples we need a multi fasta alignment of our sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat *.fas > aligned_pseudogenomes.aln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the way the pseudogenomes were constructed resulting in them being the same length we do not have to perform a mult sequence alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "1. How many sequences in the multiple sequence alignment file of pseudogenomes?\n",
    "2. What is the largest and mean sequence length? (Hint: Use assembly-stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the reference genome to the multiple sequence alignment\n",
    "Sometimes you may also want to include the reference genome used in the mapping step in your tree. To do this add the reference sequence to the multifasta alignment of your samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat ../ref/Styphi_CT18.fa aligned_pseudogenomes.aln > ref_and_aligned_pseudogenomes.aln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it would be useful to look at your alignment in a multiple sequence alignment viewer e.g. seaview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaview &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your understanding\n",
    "1. How many sequences in the multiple sequence alignment file of reference and pseudogenomes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask repetitive regions (optional but good practice)\n",
    "\n",
    "Bases called in repetitive regions may not be true variation (e.g. due to misalignment of reads) and may affect/compromise the core phylogenetic signal. Therefore it is good practice to identify known repetitive regions and mask these out from your alignment.\n",
    "\n",
    "To achieve this, either a file of known regions for the reference you aligned to will exist (see the literature) or one can be generated by matching the reference genome against itself (to identify repeat regions) with e.g. Mummer and Phast to identify prophage. We won't cover this here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a tree with iqtree\n",
    "Now that we have a multiple sequence alignment, we can use IQ-TREE to build a maximum likelihood phylogeny.\n",
    "\n",
    "Calculating a phylogeny on whole genome sequences can be very time consuming. We can speed this up by only using the variable sites (SNPs). However, we need to be aware that only including variable sites can affect the evolutionary rate estimates made by phylogenetics software - therefore, we need to account for the sites we remove in our analysis.\n",
    "\n",
    "We will use snp-sites to do this. You can view the options for snp-sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp-sites -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, remove all the invariant sites and create a SNP-only multiple sequence alignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp-sites -o ref_and_aligned_pseudogenomes.snps.aln ref_and_aligned_pseudogenomes.aln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how many invariant sites were removed (and what proportion of A, T, G, C they were) using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp-sites -C ref_and_aligned_pseudogenomes.aln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the options for IQ-TREE below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqtree -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the tree with IQ_TREE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqtree \\\n",
    "    -fconst $( snp-sites -C ref_and_aligned_pseudogenomes.aln ) \\\n",
    "    -alrt 1000 -B 1000 -m MFP -czb \\\n",
    "    -s pseudogenomes.snpsites.aln \\\n",
    "    -nt AUTO \\\n",
    "    -ntmax 2 \\\n",
    "    -mem 2GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the command below, we:\n",
    "\n",
    "specify the multiple sequence alignment using -s clean.full.SNPs.aln\n",
    "ask IQ-TREE to take account of missing invariant sites using -fconst $(snp-sites -C clean.full.aln)\n",
    "specify an evolutionary model we want IQ-TREE to use -m GTR+F+I\n",
    "tell IQ-TREE to use a maximum of 2 CPUs (threads) and 2GB memory -T 2 -mem 2G\n",
    "perform 1000 ultrafast bootstraps -B 1000\n",
    "use sample M66 as an outgroup -o M66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our maximum likelihood tree is labelled XXX.treefile. The treefile suffix is not always correctly identified by many tools, so we'll relabel this as something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp clean.full.SNPs.aln.treefile clean.full.SNPs.aln.tre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the raw text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat clean.full.SNPs.aln.tre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it is better if we visualise this using figtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figtree clean.full.SNPs.aln.tre &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root the phylogeny\n",
    "\n",
    "The trees generated by iqtree and gubbins are unrooted, but we may want to apply some evolutionary direction to them. One strategy for rooting a tree is called _midpoint rooting_. Midpoint rooting involves locating the midpoint of the longest path between any two tips and putting the root in that location. Note that this does not necessarily infer the true root, and this should be used with caution.\n",
    "\n",
    "To midpoint root our tree, we will use a simple script written in python that uses the ete package. You can examine the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less midpoint.root.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Python script to midpoint root a tree](img/midpoint.root.image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this script to midpoint root the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python midpoint.root.py gubbins.final_tree.tre > gubbins.final_tree.midpoint.tre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise this in figtree. How does it compare to the unrooted version?\n",
    "\n",
    "Another common strategy for rooting the tree is _outgroup rooting_. This is the preferred approach for bacterial datasets. Outgroup rooting involves including one or more sequences in the analysis that are more distantly related to our sequences of interest than they are to one another. These sequence are usually referred to as _outgroups_. The root estimate is then simply the point at which the outgroup(s) join the tree. The best possible outgroups are those available which are most closely related to our sequences of interest but different enough to .... Examples.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side Note:\n",
    "Often you may want to incorporate a ‘finished reference genome’ into your tree e.g. to use as an outgroup. (Explain what an outgroup is and why you may want to use it) or to see how your samples/isolates relate to them. If there is no sequence data available for the isolate e.g. there is only a complete reference genome then one approach you can take is to shred the reference genome (fasta file) and make simulated reads (remember it is a haploid genome) and treat the simulated data as another sample and process it like the other samples. You will then have a ‘pseudogenome’ of the sample that will be included in the ref_and_aligned_pseudogenomes.fas file at this stage. The practical aspect of this is beyond the scope of this tutorial. The article below lists some popular tools for simulating reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up!\n",
    "\n",
    "Clean up any intermediate files that were generated during the analysis that you no longer require. This is always an important last step of any analysis as sequence data analysis files can use up large amounts of disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm *.trim.fastq.gz\n",
    "rm *.sub.fastq.gz\n",
    "Rm *.html\n",
    "rm *.sam\n",
    "rm ERR5243693.bam*\n",
    "rm ERR5243695.bam*\n",
    "rm ERR5243699.bam*\n",
    "rm ERR5243693.vcf.gz*\n",
    "rm ERR5243695.vcf.gz*\n",
    "rm ERR5243699.vcf.gz*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to the next section: [Phylogeny and Metadata](metadata.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
